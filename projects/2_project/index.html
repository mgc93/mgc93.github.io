<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Learned Impatience | Miruna Cotet </title> <meta name="author" content="Miruna Cotet"> <meta name="description" content="Do people discount delayed reward information relative to immediate reward information, even if the timing of the information has no impact on the delivery of the reward?"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%97%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mgc93.github.io/projects/2_project/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Miruna</span> Cotet </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Learned Impatience</h1> <p class="post-description">Do people discount delayed reward information relative to immediate reward information, even if the timing of the information has no impact on the delivery of the reward?</p> </header> <article> <p>   <img src="https://images.unsplash.com/photo-1499636136210-6f4ee915583e?ixlib=rb-4.0.3&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb" alt="Untitled" width="700">  </p> <h2 id="-about">🔭 About</h2> <hr> <p>Often choices involve immediate as well as delayed rewards. If immediate rewards are preferentially processed compared to delayed rewards, behavior will be suboptimal. Overeating, overspending, or procrastinating are examples of such behavior.</p> <p>To study this effect in the lab, we proposed a novel task in which subjects faced choices between stimuli with lower total rewards, but higher immediate rewards and stimuli with higher total rewards, but lower immediate rewards. Subjects will be biased if they tend to maximize immediate rewards instead of total rewards. Presenting immediate reward feedback from the current choice and the delayed reward feedback from the previous choice simultaneously allowed us to study to what degree attention can explain this phenomenon.</p> <h2 id="-research-question">🔍 Research question</h2> <hr> <p>Do people discount <strong>delayed reward</strong> information relative to <strong>immediate reward</strong> information, even if the timing of the information has no impact on the delivery of the reward?</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_1-480.webp 480w,/assets/img/project_2_images/project_2_fig_1-800.webp 800w,/assets/img/project_2_images/project_2_fig_1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Imagine you’re in a situation where you have to decide which action to take. For instance eat cake ( 🍰 ) or an apple ( 🍎 ).</p> <p>Usually actions have multiple consequences - some immediate, others delayed.</p> <ul> <li>If you eat the apple ( 🍎 ) now - it might not be as pleasurable as the cake, but you save some calories from your diet.</li> <li>If you eat the cake ( 🍰 ) - you get the small reward now, but you might regret it later.</li> </ul> <p>Next time when you’re in the same situation, you’ll consider what to do based on your previous experience. Will the ordering of the immediate and delayed rewards affect your decision?</p> <p>Even though in this case, you would be better off choosing the healthy option ( 🍎 ) now since you get a bigger <strong>total</strong> reward, you might instead choose the unhealthy option ( 🍰 ) because the <strong>immediate</strong> reward is higher. Then you would be <strong>overweighting immediate consequences</strong>.</p> <p>Examples of suboptimal behaviors like this include: overeating, overspending, not working hard enough, exercising too little, not saving enough and so on.</p> <p>In this project, we study this kind of learning situation in a controlled setting. To study this effect in the lab, we proposed a novel task in which subjects faced choices between stimuli with lower total rewards, but higher immediate rewards and stimuli with higher total rewards, but lower immediate rewards. Subjects will be biased if they tend to maximize immediate rewards instead of total rewards. Presenting immediate reward feedback from the current choice and the delayed reward feedback from the previous choice simultaneously allowed us to study to what degree attention can explain this phenomenon.</p> <h2 id="-methods">👾 Methods</h2> <hr> <p><strong>Task</strong></p> <p>In the experiment, subjects were faced with choices between two abstract images in each round or trial. Each option had two reward points, one immediate and one delayed. The goal was to accumulate as many points as possible by choosing the images with the higher total rewards since the points were transformed into money that was paid at the end of the experiment. The points were shown on top of the chosen image on the feedback screen (Figure 1). The immediate feedback was presented simultaneously with the delayed feedback from the previous choice.</p> <p>In some trials, subjects faced a choice between an option with a higher immediate reward but a lower total reward than the alternative. Choosing the former option is a mistake, but one that is consistent with discounting delayed reward information. We also measured subjects’ eye movements during the task which allowed us to determine whether any discounting could be attributed to biased visual attention.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_2-480.webp 480w,/assets/img/project_2_images/project_2_fig_2-800.webp 800w,/assets/img/project_2_images/project_2_fig_2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1. The choice stage is illustrated on the first and third screens. The feedback stage is illustrated on the second and fourth screens. The top image and number illustrate the chosen stimuli on the current trial and its immediate payoff, while the bottom image and the number illustrate the chosen stimuli on the previous trial and its delayed payoff. A randomly generated time interval between two and six seconds was added after each choice and feedback screen. Subjects had a maximum of three seconds to make their choice. If no choice was made within this time, one stimulus was chosen randomly by the computer. The feedback screen was presented for two seconds. </div> <p><strong>Design</strong></p> <p>Stimuli: 6 abstract art images</p> <p>Trials: 105 binary choices</p> <p>Each stimulus had: &lt;immediate reward, delayed reward&gt; + small random number from &lt;{0,1,2,3}, {0,1,2,3}&gt; to make learning more difficult.</p> <p>Options can be either:</p> <ul> <li>rising: immediate &lt; delayed</li> <li>falling: immediate &gt; delayed</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_3-480.webp 480w,/assets/img/project_2_images/project_2_fig_3-800.webp 800w,/assets/img/project_2_images/project_2_fig_3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 2. Between-subjects conditions in the experiment and each stimulus reward within conditions. </div> <p>Goal: collect as many points as possible by choosing the stimuli with the highest total payoffs</p> <p>Potential bias: maximize immediate instead of total rewards</p> <p>Subjects: 90 (behavior), 75 (eye-tracking), 89 (modeling)</p> <p>Eye-tracking: online using webcam eye-tracking with the Webgazer library in jsPsych (a javascript based library for psychology experiments that you can customize).</p> <p><strong>More about webcam eye-tracking</strong></p> <p>Because I collected data during the pandemic, we decided to use online webcam eye-tracking. The library that made this possible was developed by <a href="https://webgazer.cs.brown.edu/" rel="external nofollow noopener" target="_blank">Papoutsaki, Sangkloy, Laskey, Daskalova, Huang and Hays (2016)</a> and was incorporated into jsPsych by one of my colleagues (<a href="https://www.cambridge.org/core/journals/judgment-and-decision-making/article/webcambased-online-eyetracking-for-behavioral-research/B726E77B68A76577F9BC6BB8F1EBC6E4" rel="external nofollow noopener" target="_blank">Yang and Krajbich, 2023</a>). I implemented it in my own code for the task. Although the precision is much lower than with lab eye-tracking, it is useful when showing few stimuli on the screen (in this case 2 images).</p> <p><strong>Timeline of the experiment</strong></p> <p>Subjects did a short initial eye-tracking calibration and we exclude them if they fail. Then they read the instructions and answered some questions to make sure they understood them. They then did a longer eye-tracking calibration and go through the task and at the end answer a few memory surveys. During the task we do some additional eye-tracking validations and exclude subjects who fail 2 out of the 4 validations from the eye-tracking analysis to preserve good data quality.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_4-480.webp 480w,/assets/img/project_2_images/project_2_fig_4-800.webp 800w,/assets/img/project_2_images/project_2_fig_4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 3. Timeline of the experiment. </div> <h2 id="--results">🐳 Results</h2> <hr> <h3 id="-behavioral-results">🍪 Behavioral Results</h3> <p>Subjects were able to learn the value of the stimuli as evidenced by overall accuracy levels above chance (M = 0.72, SD = 0.45).</p> <p>They were also more likely to choose higher total value stimuli (tested using mixed effect logistic regression with total reward as fixed effect, choice in each trial as the outcome variable and random intercept and slope at subject level; estimate for the fixed effect of total reward was 0.30, SE = 0.02, 95% CI = [0.26, 0.33], p &lt; .001).</p> <p>For the same total reward level, the option with the higher immediate reward was more likely to be chosen compared with the option with the lower immediate reward (Figure 4).</p> <p>To test for the presence of this learning bias, we used a mixed effects logistic regression with outcome variable the choice of right stimulus in a trial and as predictors the difference between right and left option in the experienced average immediate reward and delayed reward. Both coefficients were significantly positive with the one tracking immediate reward being higher than the one tracking delayed reward (Figure 5; b = 0.37, SE = 0.02, 95% CI = [0.32, 0.42], p &lt; .001; b = 0.27, SE = 0.02, 95% CI = [0.22, 0.32], p &lt; .001). A Likelihood Ratio Test comparing whether the coefficient of the immediate reward and the delayed reward were different was significant (X2 (4, N = 90) = 257.87, p &lt; .001)).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_5-480.webp 480w,/assets/img/project_2_images/project_2_fig_5-800.webp 800w,/assets/img/project_2_images/project_2_fig_5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 4. Behavioral bias across subjects. Probability of choosing a stimulus given that it is in the choice set as a function of the total payoff of the stimulus for each condition. For the same total value of the option, the stimulus with the higher immediate reward (first number) is more likely to be chosen compared with the stimulus with the lower immediate reward (second number). There were two conditions (red and blue) with two separate sets of options. For each total option value, one condition’s option had the reverse temporal order of rewards compared to the other condition. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_6-480.webp 480w,/assets/img/project_2_images/project_2_fig_6-800.webp 800w,/assets/img/project_2_images/project_2_fig_6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 5. Behavioral results. A. Probability of choosing the right stimulus from a mixed effects logistic regression with difference between right and left option in the immediate and delayed average experienced rewards. Subjects put more weight on the immediate rewards than the delayed rewards. </div> <p>To test whether this behavioral bias increased over the course of the experiment, we added interaction coefficients with trial number to the previous mixed effects logistic regression. The interaction of trial number and experienced immediate reward was positive and significant (b = 0.34, SE = 0.04, 95% CI = [0.26, 0.43], p &lt; .001), while the coefficient for the interaction of trial number and experienced delayed reward was also positive (b = 0.19, SE = 0.04, 95% CI = [0.11, 0.26], p &lt; .001), but was smaller and significantly different (X2(4, N = 90) = 139.11, p &lt; .001).</p> <h3 id="response-time-results">⌚Response Time Results</h3> <p>Response times result also show evidence consistent with the behavioral bias. First, in a lot of lab experiments, RT decreases with absolute value difference and decreases with overall value. This is also the case in this experiment (Figure 6).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_7-480.webp 480w,/assets/img/project_2_images/project_2_fig_7-800.webp 800w,/assets/img/project_2_images/project_2_fig_7-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 6. (left) RT decreases with absolute value difference, though is slightly lower when the two options are identical, i.e. value difference = 0. (right) RT also decreases with overall value. </div> <p>Moreover, in this experiment we can look separately of these effect on RT for immediate and delayed rewards separately to see if RT is more responsive to immediate compared to delayed rewards, which would be in line with the behavioral bias present in choices.</p> <p>Both immediate and delayed value differences decrease RT (Figure 7, immediate effect &gt; delayed effect: X2(8, N = 90) = 361, p&lt;.001). However, only immediate overall value decreases RT (Figure 8).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_8-480.webp 480w,/assets/img/project_2_images/project_2_fig_8-800.webp 800w,/assets/img/project_2_images/project_2_fig_8-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 7. (left) RT decreases with absolute value difference for immediate and (right) for delayed rewards. The immediate effect is larger than the delayed effect. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_9-480.webp 480w,/assets/img/project_2_images/project_2_fig_9-800.webp 800w,/assets/img/project_2_images/project_2_fig_9-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 8. (left) RT decreases with overall immediate value. (right) RT doesn’t decrease with overall delayed value. </div> <p>Therefore, the bias to choose based on immediate rewards rather than consider immediate and delayed rewards equally seems to also be present when analyzing subjects’ RTs.</p> <h3 id="-modeling-results">📐 Modeling Results</h3> <p>We assume that this preference for immediate feedback manifests through reinforcement learning. Neurophysiology studies have shown that delaying a reward, even by a few seconds, reduces the response of dopamine neurons and neuroimaging studies have confirmed a decreased hemodynamic response to delayed rewards in the ventral striatum. Neuroimaging studies have also shown that the Hippocampus is selectively sensitive to delayed feedback, while the Ventral Striatum is selectively sensitive to immediate feedback and a double dissociation in learning exists between amnesiac and Parkinson’s patients. </p> <p><strong>Model</strong></p> <p>We fit a modified Reinforcement Learning Drift Diffusion Model to the data and confirmed that subjects generally learned faster for immediate rewards compared to delayed rewards. This type of model combines a Reinforcement Learning model based on the Rescorla-Wagner rule for the value of each stimulus with a Drift Diffusion Model that accounts for both choices and RTs. Instead of using the logistic function to transform values into action probabilities, we use the DDM model to predict not only choices, but also response times (see project on <a href="https://www.notion.so/How-cognitive-modeling-can-identify-response-biases-in-negotiations-464e9b02091a4d3285f23f11ac212e19?pvs=21" rel="external nofollow noopener" target="_blank">cognitive modeling in negotiation</a> for additional explanation about the DDM).</p> <p>Given that each stimulus (s) was associated with two rewards, one immediate and one delayed ($r^{I},r^{D}$ ), the total value for a stimulus was the sum of the predicted values for the immediate value and the delayed value ($V_{k}(s_{k})$). The two values generate two different prediction errors, one for the immediate reward and one for the delayed reward on each trial ($k$). The learning rate controls ($\alpha^{I}, \alpha^{D}$) how much expectations about the value of the stimuli are updated. The predicted value of a stimulus is the total of the immediate value and the delayed value.</p> <p>The priors for the parameters of interest were chosen to be vague to have minimal influence on the posterior. Both learning rates and the weight of the delayed reward have beta distributed priors with shape parameters equal to one.</p> \[V^{I}_{k+1}(s_{k}) = V^{I}_{k}(s_{k}) + \alpha^{I}(r^{I}_{k} - V^{I}_{k}(s_{k})\] \[V^{D}_{k+1}(s_{k}) = V^{D}_{k}(s_{k}) + \alpha^{D}(r^{D}_{k} - V^{D}_{k}(s_{k})\] \[V_{k}(s_{k}) = V^{I}_{k}(s_{k}) + V^{D}_{k}(s_{k})\] \[v \sim d(V_{k,correct(s_{k})}-V_{k,incorrect(s_{k})})\] \[RT_{k,correct} \sim Wiener(a, t, z = 0.5, v)\] \[RT_{k,incorrect} \sim Wiener(a,t,1-z = 0.5,-v)\] <p>We found higher learning rates for immediate rewards than delayed rewards, using a paired t-test (<em>t</em>(89) = 2.70, p = 0.008).</p> <p><strong>Fitting procedure</strong></p> <p>The software Stan was used to find the best fitting parameters for each subject separately. Estimates of the posteriors for each parameter were obtained using Monte-Carlo Markov Chain sampling method. For each subject, four chains were run in parallel. To construct posterior distributions, each chain was sampled for 10,000 iterations including an initial burn-in period of 5,000 samples. The potential scale reduction factor (PSRF; Brooks &amp; Gelman, 1998) or R-hat is used to indicate chain convergence. This method compares the between and within chain estimates for model parameters. A value near smaller than 1.05 indicates convergence. To check stability of the estimates, effective sample size is used (ESS). ESS is the effective number of steps in the MCMC chain after the autocorrelation is factored out (Kruschke, 2020).</p> <p><strong>Model validation</strong></p> <p>To check whether the model mimics the data well, a posterior predictive check was conducted. For each subject, the mean posterior estimate was used for each parameter to generate 100 simulations of choices in the experiment using the actual experimental trials.</p> <p>We compute choice accuracy for the experiment, as well as choice accuracy for each possible choice set type in the experiment. The choice set could be congruent (worse option rising, better option falling), incongruent (worse option falling, better option rising), both falling options, both rising options and same total payoff. The model can account for the choice data quite well (Figure 9).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_10-480.webp 480w,/assets/img/project_2_images/project_2_fig_10-800.webp 800w,/assets/img/project_2_images/project_2_fig_10-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 9. A.Average accuracy over trials across subjects in data and the simulated data using the mean posterior values of each subject for each parameter and model. B. Average accuracy over each block of trials across subjects in the data and the simulated data for each type of choice set separately. </div> <h3 id="-eye-tracking-results">👀 Eye-tracking Results</h3> <p>Turning to the eye tracking data, subjects were more likely to dwell on the immediate reward when controlling for trial level prediction errors and expected values for immediate and delayed rewards (mixed effects regression with outcome variable difference in proportion of dwell time to immediate minus delayed reward within a trial and as predictors absolute prediction error for immediate and delayed rewards, expected value for immediate and delayed rewards and random intercept at subject level and trial level, the fixed effect for the intercept was 0.095, S.E. = 0.035, 95% CI = [0.026, 0.163], p = .007). However, this effect did not correlate with the behavioral bias across subjects (immediate reward r(72) = -0.097, p = .41, delayed reward r(72) = 0.046, p = .70 for correlation between subject level coefficients for immediate or delayed reward and subject level coefficients for the intercept for dwell time advantage for immediate versus delayed reward).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_2_images/project_2_fig_11-480.webp 480w,/assets/img/project_2_images/project_2_fig_11-800.webp 800w,/assets/img/project_2_images/project_2_fig_11-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_2_images/project_2_fig_11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 10. Attention to Feedback within a Trial. Dwell Bin is the time point within a trial in steps of 250 ms e.g. [0, 250), [250, 500), [500, 750) etc. Red dots and bars represent mean proportion dwell to immediate reward within the respective time bin and 95% bootstrapped confidence intervals. Black dots and lines are subject level effects. </div> <h2 id="conclusions">🏁 Conclusions</h2> <hr> <p>Our results show that people are biased towards options that yield immediate reward information. Visual attention appears to play a role in this phenomenon, though this result was only observed in the aggregate, not at the subject level. This work sheds new light on the fundamental problem of temporal discounting, indicating that it is, at least in part, an issue of reward information and not just reward delivery.</p> <h2 id="-outcomes">🌟 Outcomes</h2> <hr> <p>Won a $2,250 grant for the project: Decision Sciences Collaborative Research Grant at the Ohio State University, 2020.</p> <p>Presented the project at the <a href="https://www.fox.temple.edu/faculty-research/institutes-centers/center-applied-research-decision-making/interdisciplinary-symposium-decision-neuroscience-2023" rel="external nofollow noopener" target="_blank">Interdisciplinary Symposium in Decision Neuroscience, 2023</a>.</p> <p>Presented a poster of the project at EADM Summer School on Learning and Decision Making, 2022.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Miruna Cotet. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>